{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "geographic-chest",
   "metadata": {},
   "source": [
    "# 随机森林1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "straight-importance",
   "metadata": {},
   "source": [
    "## 1 集成算法概述"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sophisticated-reservoir",
   "metadata": {},
   "source": [
    "集成学习（ensemble learning）是时下非常流行的机器学习算法，它本身不是一个单独的机器学习算法，而是通过在数据上构建多个模型，集成所有模型的建模结果。基本上所有的机器学习领域都可以看到集成学习的身影，在现实中集成学习也有相当大的作用，它可以用来做市场营销模拟的建模，统计客户来源，保留和流失，也可用来预测疾病的风险和病患者的易感性。在现在的各种算法竞赛中，随机森林，梯度提升树（GBDT），Xgboost等集成算法的身影也随处可见，可见其效果之好，应用之广。"
   ]
  },
  {
   "cell_type": "raw",
   "id": "elementary-algeria",
   "metadata": {},
   "source": [
    "集成算法的目标：\n",
    "集成算法会考虑多个评估器的建模结果，汇总之后得到一个综合的结果，以此来获取比单个模型更好的回归或分类表现。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "secret-program",
   "metadata": {},
   "source": [
    "多个模型集成成为的模型叫做集成评估器（ensemble estimator），组成集成评估器的每个模型都叫做基评估器（base estimator）。通常来说，有三类集成算法：装袋法（Bagging），提升法（Boosting）和stacking。"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "reduced-northern",
   "metadata": {},
   "source": [
    "![image.png](https://pic4.zhimg.com/80/v2-dd9c194119f24b35b478b4262cad54db_720w.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "suburban-clerk",
   "metadata": {},
   "source": [
    "装袋法的核心思想是构建多个**相互独立的评估器**，然后对其预测进行平均或多数表决原则来决定集成评估器的结果。装袋法的代表模型就是随机森林。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lesser-beast",
   "metadata": {},
   "source": [
    "提升法中，**基评估器是相关的**，是按顺序一一构建的。其核心思想是结合弱评估器的力量一次次对难以评估的样本进行预测，从而构成一个强评估器。提升法的代表模型有Adaboost和梯度提升树。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "related-arrow",
   "metadata": {},
   "source": [
    "## 2 sklearn中的集成算法"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "furnished-shaft",
   "metadata": {},
   "source": [
    "- sklearn中的集成算法模块**ensemble**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "annual-chosen",
   "metadata": {},
   "source": [
    "## RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "marked-maldives",
   "metadata": {},
   "source": [
    "**老的参数：criterion、max_depth、min_samples_leaf、min_samples_split、max_features、min_impurity_decrease，可见前面决策树**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "amino-robin",
   "metadata": {},
   "source": [
    "**新的参数如下：**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "taken-melbourne",
   "metadata": {},
   "source": [
    "**n_estimators**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "welcome-calvin",
   "metadata": {},
   "source": [
    "这是森林中树木的数量，即基基评估器的数量。这个参数对随机森林模型的精确性影响是单调的，**n_estimators越大，模型的效果往往越好**。但是相应的，任何模型都有决策边界，n_estimators达到一定的程度之后，随机森林的精确性往往不在上升或开始波动，并且，n_estimators越大，需要的计算量和内存也越大，训练的时间也会越来越长。对于这个参数，我们是渴望在训练难度和模型效果之间取得平衡。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "informal-repeat",
   "metadata": {},
   "source": [
    "n_estimators的默认值在现有版本的sklearn中是10，但是在即将更新的0.22版本中，这个默认值会被修正为100。这个修正显示出了使用者的调参倾向：要更大的n_estimators。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "serious-charleston",
   "metadata": {},
   "source": [
    "树模型的优点是简单易懂，可视化之后的树人人都能够看懂，可惜随机森林是无法被可视化的。所以为了更加直观地让大家体会随机森林的效果，我们来进行一个随机森林和单个决策树效益的对比。我们依然使用红酒数据集。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "later-boutique",
   "metadata": {},
   "source": [
    "**1、导入我们需要的包**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "opposite-fantasy",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import load_wine"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
