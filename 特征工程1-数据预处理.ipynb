{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "confirmed-specialist",
   "metadata": {},
   "source": [
    "# 数据预处理与特征工程1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "divided-package",
   "metadata": {},
   "source": [
    "想象一下未来美好的一天，你学完了菜菜的课程，成为一个精通各种算法和调参调库的数据挖掘工程师了。某一天你从你的同事，一位药物研究人员那里，得到了一份病人临床表现的数据。药物研究人员用前四列数据预测一下最后一数据，还说他要出差几天，可能没办法和你一起研究数据了，希望出差回来以后，可以有个初步分析结果。于是你就看了看数据，看着很普通，预测连续型变量，好说，导随机森林回归器调出来，调参调呀调，MSE很小，跑了个还不错的结果。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "advisory-substance",
   "metadata": {},
   "source": [
    "![image.png](https://pic1.zhimg.com/80/v2-f523da29c40e71622a54eb7eab458bdc_720w.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sharing-notice",
   "metadata": {},
   "source": [
    "几天后，你同事出差回来了，准备要一起开会了，会上你碰见了和你同事在同一个项目里工作的统计学家。他问起你的分析结果，你说你已经小有成效了，统计学家很吃惊，他说：“不错呀，这组数据问题太多，我都分析不出什么来。”"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fancy-pitch",
   "metadata": {},
   "source": [
    "你心里可能咯噔一下，忐忑地回答说：“我没听说数据有什么问题呀。”"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "thorough-prospect",
   "metadata": {},
   "source": [
    "于是统计学家说：“诶？没人告诉你说，最后一列数据如果取个对数，结果会更好吗？”"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "surprising-european",
   "metadata": {},
   "source": [
    "你内心毫无波动：“没。”"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "verbal-indiana",
   "metadata": {},
   "source": [
    "统计学家：“诶那你肯定听说了第四列数据有点问题吧，这个特征的取值范围是1~10，0是表示缺失值的。而且他们输入数据的时候出错，很多10都被录入成0了，现在分不出来了。”"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "included-truth",
   "metadata": {},
   "source": [
    "你：”......“"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "affecting-blind",
   "metadata": {},
   "source": [
    "统计学家：”还有第二列和第三列数据基本是一样的，相关性太强了。“"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "designing-cleanup",
   "metadata": {},
   "source": [
    "你：”这个我发现了，不过这两个特征在预测中的重要性都不高，无论其他特征怎样出错，我这边结果里显示第一列的特征是最重要的，所以也无所谓啦。“"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "flying-catering",
   "metadata": {},
   "source": [
    "统计学家：“啥？第一列不就是编号吗？”"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "annual-diesel",
   "metadata": {},
   "source": [
    "你：“不是吧。”"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stylish-subdivision",
   "metadata": {},
   "source": [
    "统计学家：“哦我想起来了！第一列就是编号，不过那个编号是我们根据第五列排序之后编上去的！这个第一列和第五列是由很强的联系，但是毫无意义啊！”"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "colored-fraction",
   "metadata": {},
   "source": [
    "老血喷了一屏幕，数据挖掘工程师卒。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "therapeutic-iraqi",
   "metadata": {},
   "source": [
    "这个悲惨又可爱的故事来自《数据挖掘导论》，虽然这是故事里的状况十分极端，但我还是想把这段对话作为今天这章的开头，博大家一笑（虽然可能听完就泪流满面了）。在过去两周，我们已经讲了两个算法：决策树和随机森林，我们通过决策树带大家认识了sklearn，通过随机森林讲解了机器学习中调参的基本思想，现在可以说，只要上过前面两堂课的，人人都会调随机森林和决策树的分类器了，而我呢，也只需要跟着各大机器学习书籍的步伐，给大家一周一个算法带着讲解就是了。如果这样的话，结果可能就是，大家去工作了，遇到了一个不那么靠谱的同事，给了你一组有坑的数据，最后你就一屏幕老血吐过去，牺牲在数据行业的前线了。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "concerned-edinburgh",
   "metadata": {},
   "source": [
    "**数据不给力，再高级的算法都没有用。**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "worthy-ferry",
   "metadata": {},
   "source": [
    "## 数据挖掘的五大流程："
   ]
  },
  {
   "cell_type": "markdown",
   "id": "upper-thomson",
   "metadata": {},
   "source": [
    "**1. 获取数据**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ambient-commerce",
   "metadata": {},
   "source": [
    "**2. 数据预处理**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "prospective-index",
   "metadata": {},
   "source": [
    "数据预处理是从数据中检测，纠正或删除损坏，不准确或不适用于模型的记录的过程\n",
    "可能面对的问题有：数据类型不同，比如有的是文字，有的是数字，有的含时间序列，有的连续，有的间断。也可能，数据的质量不行，有噪声，有异常，有缺失，数据出错，量纲不一，有重复，数据是偏态，数据量太大或太小<br>\n",
    "数据预处理的目的：让数据适应模型，匹配模型的需求"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "overhead-treaty",
   "metadata": {},
   "source": [
    "**3. 特征工程：**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "selective-complement",
   "metadata": {},
   "source": [
    "特征工程是将原始数据转换为更能代表预测模型的潜在问题的特征的过程，可以通过挑选最相关的特征，提取特征以及创造特征来实现。其中创造特征又经常以降维算法的方式实现。 可能面对的问题有：特征之间有相关性，特征和标签无关，特征太多或太小，或者干脆就无法表现出应有的数据现象或无法展示数据的真实面貌<br>\n",
    "特征工程的目的：1) 降低计算成本，2) 提升模型上限"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unauthorized-kidney",
   "metadata": {},
   "source": [
    "**4. 建模，测试模型并预测出结果**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baking-difference",
   "metadata": {},
   "source": [
    "**5. 上线，验证模型效果**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "religious-charm",
   "metadata": {},
   "source": [
    "## 1、sklearn中的数据预处理和特征工程"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "recovered-puzzle",
   "metadata": {},
   "source": [
    "sklearn中包含众多数据预处理和特征工程相关的模块，虽然刚接触sklearn时，大家都会为其中包含的各种算法的广度深度所震惊，但其实sklearn六大板块中有两块都是关于数据预处理和特征工程的，两个板块互相交互，为建模之前的全部工程打下基础。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "agreed-evidence",
   "metadata": {},
   "source": [
    "![image.png](https://pic3.zhimg.com/80/v2-426ddeb54406fa491a494e8c88940f52_720w.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unable-assist",
   "metadata": {},
   "source": [
    "- 模块preprocessing：几乎包含数据预处理的所有内容\n",
    "- 模块Impute：填补缺失值专用\n",
    "- 模块feature_selection：包含特征选择的各种方法的实践\n",
    "- 模块decomposition：包含降维算法"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "generous-animal",
   "metadata": {},
   "source": [
    "## 2、数据预处理 Preprocessing & Impute"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "specific-pendant",
   "metadata": {},
   "source": [
    "### 2.1 数据无量纲化"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "proof-creation",
   "metadata": {},
   "source": [
    "在机器学习算法实践中，我们往往有着将不同规格的数据转换到同一规格，或不同分布的数据转换到某个特定分布的需求，这种需求统称为将数据“无量纲化”。譬如梯度和矩阵为核心的算法中，譬如逻辑回归，支持向量机，神经网络，无量纲化可以加快求解速度；而在距离类模型，譬如K近邻，K-Means聚类中，无量纲化可以帮我们提升模型精度，避免某一个取值范围特别大的特征对距离计算造成影响。（一个特例是决策树和树的集成算法们，对决策树我们不需要无量纲化，决策树可以把任意数据都处理得很好。）"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "popular-technique",
   "metadata": {},
   "source": [
    "数据的无量纲化可以是线性的，也可以是非线性的。线性的无量纲化包括中心化（Zero-centered或者Mean-subtraction）处理和缩放处理（Scale）。中心化的本质是让所有记录减去一个固定值，即让数据样本数据平移到某个位置。缩放的本质是通过除以一个固定值，将数据固定在某个范围之中，取对数也算是一种缩放处理。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "floating-winning",
   "metadata": {},
   "source": [
    "- **preprocessing.MinMaxScaler**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "entitled-pilot",
   "metadata": {},
   "source": [
    "当数据(x)按照最小值中心化后，再按极差（最大值 - 最小值）缩放，数据移动了最小值个单位，并且会被收敛到[0,1]之间，而这个过程，就叫做**数据归一化(Normalization，又称Min-Max Scaling)**。注意，Normalization是归一化，不是正则化，真正的正则化是regularization，不是数据预处理的一种手段。归一化之后的数据服从正态分布，公式如下："
   ]
  },
  {
   "cell_type": "markdown",
   "id": "noted-coaching",
   "metadata": {},
   "source": [
    "![image.png](https://www.zhihu.com/equation?tex=x%5E%2A+%3D+%5Cfrac%7Bx+-+min%28x%29%7D%7Bmax%28x%29-min%28x%29%7D%5C%5C)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "surrounded-negotiation",
   "metadata": {},
   "source": [
    "在sklearn当中，我们使用**preprocessing.MinMaxScaler**来实现这个功能。MinMaxScaler有一个重要参数，feature_range，控制我们希望把数据压缩到的范围，默认是[0,1]。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "smooth-landing",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "data = [[-1, 2], [-0.5, 6], [0, 10], [1, 18]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "retained-boring",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.5</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0   1\n",
       "0 -1.0   2\n",
       "1 -0.5   6\n",
       "2  0.0  10\n",
       "3  1.0  18"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#不太熟悉numpy的小伙伴，能够判断data的结构吗？\n",
    "#如果换成表是什么样子？\n",
    "import pandas as pd\n",
    "pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "owned-momentum",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.  , 0.  ],\n",
       "       [0.25, 0.25],\n",
       "       [0.5 , 0.5 ],\n",
       "       [1.  , 1.  ]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#实现归一化\n",
    "scaler = MinMaxScaler()                             #实例化\n",
    "scaler = scaler.fit(data)                           #fit，在这里本质是生成min(x)和max(x)\n",
    "result = scaler.transform(data)                     #通过接口导出结果\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "global-flavor",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_ = scaler.fit_transform(data)                #训练和导出结果一步达成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "attended-palace",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.  , 0.  ],\n",
       "       [0.25, 0.25],\n",
       "       [0.5 , 0.5 ],\n",
       "       [1.  , 1.  ]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "graphic-footage",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1. ,  2. ],\n",
       "       [-0.5,  6. ],\n",
       "       [ 0. , 10. ],\n",
       "       [ 1. , 18. ]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler.inverse_transform(result)                    #将归一化后的结果逆转"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "radio-metallic",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 5.  ,  5.  ],\n",
       "       [ 6.25,  6.25],\n",
       "       [ 7.5 ,  7.5 ],\n",
       "       [10.  , 10.  ]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#使用MinMaxScaler的参数feature_range实现将数据归一化到[0,1]以外的范围中\n",
    "\n",
    "data = [[-1, 2], [-0.5, 6], [0, 10], [1, 18]]\n",
    "scaler = MinMaxScaler(feature_range=[5,10])         #依然实例化\n",
    "result = scaler.fit_transform(data)                 #fit_transform一步导出结果\n",
    "result\n",
    "\n",
    "#当X中的特征数量非常多的时候，fit会报错并表示，数据量太大了我计算不了\n",
    "#此时使用partial_fit作为训练接口\n",
    "#scaler = scaler.partial_fit(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "crucial-blair",
   "metadata": {},
   "source": [
    "**使用numpy来实现归一化：**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "atlantic-magic",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "X = np.array([[-1, 2], [-0.5, 6], [0, 10], [1, 18]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "objective-working",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1.0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "colonial-circuit",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1. , -0.5,  0. ,  1. ])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.min(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "possible-smart",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.,  2.])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.min(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "applicable-oregon",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.  , 0.  ],\n",
       "       [0.25, 0.25],\n",
       "       [0.5 , 0.5 ],\n",
       "       [1.  , 1.  ]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#归一化\n",
    "X_nor = (X - X.min(axis=0)) / (X.max(axis=0) - X.min(axis=0))\n",
    "X_nor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "correct-strain",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1. ,  2. ],\n",
       "       [-0.5,  6. ],\n",
       "       [ 0. , 10. ],\n",
       "       [ 1. , 18. ]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#逆转归一化\n",
    "X_returned = X_nor * (X.max(axis=0) - X.min(axis=0)) + X.min(axis=0)\n",
    "X_returned"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "focal-buddy",
   "metadata": {},
   "source": [
    "- **preprocessing.StandardScaler**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "champion-member",
   "metadata": {},
   "source": [
    "当数据(x)按均值(μ)中心化后，再按标准差(σ)缩放，数据就会服从为均值为0，方差为1的正态分布（即标准正态分布），而这个过程，就叫做**数据标准化**(Standardization，又称Z-score normalization)，公式如下："
   ]
  },
  {
   "cell_type": "markdown",
   "id": "satisfied-medium",
   "metadata": {},
   "source": [
    "![image.png](https://www.zhihu.com/equation?tex=x%5E%2A+%3D+%5Cfrac%7Bx-%CE%BC%7D%5Csigma%5C%5C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "systematic-possession",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "data = [[-1, 2], [-0.5, 6], [0, 10], [1, 18]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "looking-speaking",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StandardScaler()"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler = StandardScaler()  #实例化\n",
    "scaler.fit(data)      #fit，本质是生成均值和方差"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cleared-consultation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.125,  9.   ])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler.mean_  #查看均值的属性mean_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "surface-architect",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.546875, 35.      ])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler.var_                                         #查看方差的属性var_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "underlying-gross",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_std = scaler.transform(data)                      #通过接口导出结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "intermediate-islam",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.18321596, -1.18321596],\n",
       "       [-0.50709255, -0.50709255],\n",
       "       [ 0.16903085,  0.16903085],\n",
       "       [ 1.52127766,  1.52127766]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "asian-maple",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_std.mean()    #导出的结果是一个数组，用mean()查看均值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "seven-trout",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_std.std()    #用std()查看方差"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "municipal-fleet",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.18321596, -1.18321596],\n",
       "       [-0.50709255, -0.50709255],\n",
       "       [ 0.16903085,  0.16903085],\n",
       "       [ 1.52127766,  1.52127766]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler.fit_transform(data)     #使用fit_transform(data)一步达成结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "earlier-reality",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1. ,  2. ],\n",
       "       [-0.5,  6. ],\n",
       "       [ 0. , 10. ],\n",
       "       [ 1. , 18. ]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler.inverse_transform(x_std)    #使用inverse_transform逆转标准化"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "latin-touch",
   "metadata": {},
   "source": [
    "对于StandardScaler和MinMaxScaler来说，空值NaN会被当做是缺失值，在fit的时候忽略，在transform的时候保持缺失NaN的状态显示。并且，尽管去量纲化过程不是具体的算法，但在fit接口中，依然只允许导入至少二维数组，一维数组导入会报错。通常来说，我们输入的X会是我们的特征矩阵，现实案例中特征矩阵不太可能是一维所以不会存在这个问题。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "banner-wagner",
   "metadata": {},
   "source": [
    "- **StandardScaler和MinMaxScaler选哪个？**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "celtic-overview",
   "metadata": {},
   "source": [
    "看情况。大多数机器学习算法中，会选择StandardScaler来进行特征缩放，因为MinMaxScaler对异常值非常敏感。在PCA，聚类，逻辑回归，支持向量机，神经网络这些算法中，StandardScaler往往是最好的选择。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daily-danger",
   "metadata": {},
   "source": [
    "MinMaxScaler在不涉及距离度量、梯度、协方差计算以及数据需要被压缩到特定区间时使用广泛，比如数字图像处理中量化像素强度时，都会使用MinMaxScaler将数据压缩于[0,1]区间之中。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vulnerable-intent",
   "metadata": {},
   "source": [
    "建议先试试看StandardScaler，效果不好换MinMaxScaler。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "transparent-inclusion",
   "metadata": {},
   "source": [
    "除了StandardScaler和MinMaxScaler之外，sklearn中也提供了各种其他缩放处理（中心化只需要一个pandas广播一下减去某个数就好了，因此sklearn不提供任何中心化功能）。比如，在希望压缩数据，却不影响数据的稀疏性时（不影响矩阵中取值为0的个数时），我们会使用MaxAbsScaler；在异常值多，噪声非常大时，我们可能会选用分位数来无量纲化，此时使用RobustScaler。更多详情请参考以下列表。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "funny-handbook",
   "metadata": {},
   "source": [
    "![image.png](https://pic4.zhimg.com/80/v2-beeec3ba7bfcb638bf9161bf09bd85b3_720w.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "missing-essex",
   "metadata": {},
   "source": [
    "### 2.2 缺失值"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "temporal-elder",
   "metadata": {},
   "source": [
    "机器学习和数据挖掘中所使用的数据，永远不可能是完美的。很多特征，对于分析和建模来说意义非凡，但对于实际收集数据的人却不是如此，因此数据挖掘之中，常常会有重要的字段缺失值很多，但又不能舍弃字段的情况。因此，数据预处理中非常重要的一项就是处理缺失值。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "historical-prescription",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv(\"./datasets/Narrativedata.csv\",index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "injured-routine",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22.0</td>\n",
       "      <td>male</td>\n",
       "      <td>S</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38.0</td>\n",
       "      <td>female</td>\n",
       "      <td>C</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>26.0</td>\n",
       "      <td>female</td>\n",
       "      <td>S</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>35.0</td>\n",
       "      <td>female</td>\n",
       "      <td>S</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>35.0</td>\n",
       "      <td>male</td>\n",
       "      <td>S</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Age     Sex Embarked Survived\n",
       "0  22.0    male        S       No\n",
       "1  38.0  female        C      Yes\n",
       "2  26.0  female        S      Yes\n",
       "3  35.0  female        S      Yes\n",
       "4  35.0    male        S       No"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "blind-ghost",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 891 entries, 0 to 890\n",
      "Data columns (total 4 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   Age       714 non-null    float64\n",
      " 1   Sex       891 non-null    object \n",
      " 2   Embarked  889 non-null    object \n",
      " 3   Survived  891 non-null    object \n",
      "dtypes: float64(1), object(3)\n",
      "memory usage: 34.8+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "prostate-burden",
   "metadata": {},
   "source": [
    "- **impute.SimpleImputer**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "appropriate-eagle",
   "metadata": {},
   "source": [
    "class sklearn.impute.SimpleImputer(missing_values=nan, strategy=’mean’, fill_value=None, verbose=0, copy=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adjacent-heavy",
   "metadata": {},
   "source": [
    "在讲解随机森林的案例时，我们用这个类和随机森林回归填补了缺失值，对比了不同的缺失值填补方式对数据的影响。这个类是专门用来填补缺失值的。它包括四个重要参数："
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adolescent-carol",
   "metadata": {},
   "source": [
    "![image.png](https://pic2.zhimg.com/80/v2-66c8d10439ac1bc58f06100843b478d5_720w.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "earned-chart",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([22.  , 38.  , 26.  , 35.  , 35.  ,   nan, 54.  ,  2.  , 27.  ,\n",
       "       14.  ,  4.  , 58.  , 20.  , 39.  , 14.  , 55.  ,  2.  ,   nan,\n",
       "       31.  ,   nan, 35.  , 34.  , 15.  , 28.  ,  8.  , 38.  ,   nan,\n",
       "       19.  ,   nan,   nan, 40.  ,   nan,   nan, 66.  , 28.  , 42.  ,\n",
       "         nan, 21.  , 18.  , 14.  , 40.  , 27.  ,   nan,  3.  , 19.  ,\n",
       "         nan,   nan,   nan,   nan, 18.  ,  7.  , 21.  , 49.  , 29.  ,\n",
       "       65.  ,   nan, 21.  , 28.5 ,  5.  , 11.  , 22.  , 38.  , 45.  ,\n",
       "        4.  ,   nan,   nan, 29.  , 19.  , 17.  , 26.  , 32.  , 16.  ,\n",
       "       21.  , 26.  , 32.  , 25.  ,   nan,   nan,  0.83, 30.  , 22.  ,\n",
       "       29.  ,   nan, 28.  , 17.  , 33.  , 16.  ,   nan, 23.  , 24.  ,\n",
       "       29.  , 20.  , 46.  , 26.  , 59.  ,   nan, 71.  , 23.  , 34.  ,\n",
       "       34.  , 28.  ,   nan, 21.  , 33.  , 37.  , 28.  , 21.  ,   nan,\n",
       "       38.  ,   nan, 47.  , 14.5 , 22.  , 20.  , 17.  , 21.  , 70.5 ,\n",
       "       29.  , 24.  ,  2.  , 21.  ,   nan, 32.5 , 32.5 , 54.  , 12.  ,\n",
       "         nan, 24.  ,   nan, 45.  , 33.  , 20.  , 47.  , 29.  , 25.  ,\n",
       "       23.  , 19.  , 37.  , 16.  , 24.  ,   nan, 22.  , 24.  , 19.  ,\n",
       "       18.  , 19.  , 27.  ,  9.  , 36.5 , 42.  , 51.  , 22.  , 55.5 ,\n",
       "       40.5 ,   nan, 51.  , 16.  , 30.  ,   nan,   nan, 44.  , 40.  ,\n",
       "       26.  , 17.  ,  1.  ,  9.  ,   nan, 45.  ,   nan, 28.  , 61.  ,\n",
       "        4.  ,  1.  , 21.  , 56.  , 18.  ,   nan, 50.  , 30.  , 36.  ,\n",
       "         nan,   nan,  9.  ,  1.  ,  4.  ,   nan,   nan, 45.  , 40.  ,\n",
       "       36.  , 32.  , 19.  , 19.  ,  3.  , 44.  , 58.  ,   nan, 42.  ,\n",
       "         nan, 24.  , 28.  ,   nan, 34.  , 45.5 , 18.  ,  2.  , 32.  ,\n",
       "       26.  , 16.  , 40.  , 24.  , 35.  , 22.  , 30.  ,   nan, 31.  ,\n",
       "       27.  , 42.  , 32.  , 30.  , 16.  , 27.  , 51.  ,   nan, 38.  ,\n",
       "       22.  , 19.  , 20.5 , 18.  ,   nan, 35.  , 29.  , 59.  ,  5.  ,\n",
       "       24.  ,   nan, 44.  ,  8.  , 19.  , 33.  ,   nan,   nan, 29.  ,\n",
       "       22.  , 30.  , 44.  , 25.  , 24.  , 37.  , 54.  ,   nan, 29.  ,\n",
       "       62.  , 30.  , 41.  , 29.  ,   nan, 30.  , 35.  , 50.  ,   nan,\n",
       "        3.  , 52.  , 40.  ,   nan, 36.  , 16.  , 25.  , 58.  , 35.  ,\n",
       "         nan, 25.  , 41.  , 37.  ,   nan, 63.  , 45.  ,   nan,  7.  ,\n",
       "       35.  , 65.  , 28.  , 16.  , 19.  ,   nan, 33.  , 30.  , 22.  ,\n",
       "       42.  , 22.  , 26.  , 19.  , 36.  , 24.  , 24.  ,   nan, 23.5 ,\n",
       "        2.  ,   nan, 50.  ,   nan,   nan, 19.  ,   nan,   nan,  0.92,\n",
       "         nan, 17.  , 30.  , 30.  , 24.  , 18.  , 26.  , 28.  , 43.  ,\n",
       "       26.  , 24.  , 54.  , 31.  , 40.  , 22.  , 27.  , 30.  , 22.  ,\n",
       "         nan, 36.  , 61.  , 36.  , 31.  , 16.  ,   nan, 45.5 , 38.  ,\n",
       "       16.  ,   nan,   nan, 29.  , 41.  , 45.  , 45.  ,  2.  , 24.  ,\n",
       "       28.  , 25.  , 36.  , 24.  , 40.  ,   nan,  3.  , 42.  , 23.  ,\n",
       "         nan, 15.  , 25.  ,   nan, 28.  , 22.  , 38.  ,   nan,   nan,\n",
       "       40.  , 29.  , 45.  , 35.  ,   nan, 30.  , 60.  ,   nan,   nan,\n",
       "       24.  , 25.  , 18.  , 19.  , 22.  ,  3.  ,   nan, 22.  , 27.  ,\n",
       "       20.  , 19.  , 42.  ,  1.  , 32.  , 35.  ,   nan, 18.  ,  1.  ,\n",
       "       36.  ,   nan, 17.  , 36.  , 21.  , 28.  , 23.  , 24.  , 22.  ,\n",
       "       31.  , 46.  , 23.  , 28.  , 39.  , 26.  , 21.  , 28.  , 20.  ,\n",
       "       34.  , 51.  ,  3.  , 21.  ,   nan,   nan,   nan, 33.  ,   nan,\n",
       "       44.  ,   nan, 34.  , 18.  , 30.  , 10.  ,   nan, 21.  , 29.  ,\n",
       "       28.  , 18.  ,   nan, 28.  , 19.  ,   nan, 32.  , 28.  ,   nan,\n",
       "       42.  , 17.  , 50.  , 14.  , 21.  , 24.  , 64.  , 31.  , 45.  ,\n",
       "       20.  , 25.  , 28.  ,   nan,  4.  , 13.  , 34.  ,  5.  , 52.  ,\n",
       "       36.  ,   nan, 30.  , 49.  ,   nan, 29.  , 65.  ,   nan, 50.  ,\n",
       "         nan, 48.  , 34.  , 47.  , 48.  ,   nan, 38.  ,   nan, 56.  ,\n",
       "         nan,  0.75,   nan, 38.  , 33.  , 23.  , 22.  ,   nan, 34.  ,\n",
       "       29.  , 22.  ,  2.  ,  9.  ,   nan, 50.  , 63.  , 25.  ,   nan,\n",
       "       35.  , 58.  , 30.  ,  9.  ,   nan, 21.  , 55.  , 71.  , 21.  ,\n",
       "         nan, 54.  ,   nan, 25.  , 24.  , 17.  , 21.  ,   nan, 37.  ,\n",
       "       16.  , 18.  , 33.  ,   nan, 28.  , 26.  , 29.  ,   nan, 36.  ,\n",
       "       54.  , 24.  , 47.  , 34.  ,   nan, 36.  , 32.  , 30.  , 22.  ,\n",
       "         nan, 44.  ,   nan, 40.5 , 50.  ,   nan, 39.  , 23.  ,  2.  ,\n",
       "         nan, 17.  ,   nan, 30.  ,  7.  , 45.  , 30.  ,   nan, 22.  ,\n",
       "       36.  ,  9.  , 11.  , 32.  , 50.  , 64.  , 19.  ,   nan, 33.  ,\n",
       "        8.  , 17.  , 27.  ,   nan, 22.  , 22.  , 62.  , 48.  ,   nan,\n",
       "       39.  , 36.  ,   nan, 40.  , 28.  ,   nan,   nan, 24.  , 19.  ,\n",
       "       29.  ,   nan, 32.  , 62.  , 53.  , 36.  ,   nan, 16.  , 19.  ,\n",
       "       34.  , 39.  ,   nan, 32.  , 25.  , 39.  , 54.  , 36.  ,   nan,\n",
       "       18.  , 47.  , 60.  , 22.  ,   nan, 35.  , 52.  , 47.  ,   nan,\n",
       "       37.  , 36.  ,   nan, 49.  ,   nan, 49.  , 24.  ,   nan,   nan,\n",
       "       44.  , 35.  , 36.  , 30.  , 27.  , 22.  , 40.  , 39.  ,   nan,\n",
       "         nan,   nan, 35.  , 24.  , 34.  , 26.  ,  4.  , 26.  , 27.  ,\n",
       "       42.  , 20.  , 21.  , 21.  , 61.  , 57.  , 21.  , 26.  ,   nan,\n",
       "       80.  , 51.  , 32.  ,   nan,  9.  , 28.  , 32.  , 31.  , 41.  ,\n",
       "         nan, 20.  , 24.  ,  2.  ,   nan,  0.75, 48.  , 19.  , 56.  ,\n",
       "         nan, 23.  ,   nan, 18.  , 21.  ,   nan, 18.  , 24.  ,   nan,\n",
       "       32.  , 23.  , 58.  , 50.  , 40.  , 47.  , 36.  , 20.  , 32.  ,\n",
       "       25.  ,   nan, 43.  ,   nan, 40.  , 31.  , 70.  , 31.  ,   nan,\n",
       "       18.  , 24.5 , 18.  , 43.  , 36.  ,   nan, 27.  , 20.  , 14.  ,\n",
       "       60.  , 25.  , 14.  , 19.  , 18.  , 15.  , 31.  ,  4.  ,   nan,\n",
       "       25.  , 60.  , 52.  , 44.  ,   nan, 49.  , 42.  , 18.  , 35.  ,\n",
       "       18.  , 25.  , 26.  , 39.  , 45.  , 42.  , 22.  ,   nan, 24.  ,\n",
       "         nan, 48.  , 29.  , 52.  , 19.  , 38.  , 27.  ,   nan, 33.  ,\n",
       "        6.  , 17.  , 34.  , 50.  , 27.  , 20.  , 30.  ,   nan, 25.  ,\n",
       "       25.  , 29.  , 11.  ,   nan, 23.  , 23.  , 28.5 , 48.  , 35.  ,\n",
       "         nan,   nan,   nan, 36.  , 21.  , 24.  , 31.  , 70.  , 16.  ,\n",
       "       30.  , 19.  , 31.  ,  4.  ,  6.  , 33.  , 23.  , 48.  ,  0.67,\n",
       "       28.  , 18.  , 34.  , 33.  ,   nan, 41.  , 20.  , 36.  , 16.  ,\n",
       "       51.  ,   nan, 30.5 ,   nan, 32.  , 24.  , 48.  , 57.  ,   nan,\n",
       "       54.  , 18.  ,   nan,  5.  ,   nan, 43.  , 13.  , 17.  , 29.  ,\n",
       "         nan, 25.  , 25.  , 18.  ,  8.  ,  1.  , 46.  ,   nan, 16.  ,\n",
       "         nan,   nan, 25.  , 39.  , 49.  , 31.  , 30.  , 30.  , 34.  ,\n",
       "       31.  , 11.  ,  0.42, 27.  , 31.  , 39.  , 18.  , 39.  , 33.  ,\n",
       "       26.  , 39.  , 35.  ,  6.  , 30.5 ,   nan, 23.  , 31.  , 43.  ,\n",
       "       10.  , 52.  , 27.  , 38.  , 27.  ,  2.  ,   nan,   nan,  1.  ,\n",
       "         nan, 62.  , 15.  ,  0.83,   nan, 23.  , 18.  , 39.  , 21.  ,\n",
       "         nan, 32.  ,   nan, 20.  , 16.  , 30.  , 34.5 , 17.  , 42.  ,\n",
       "         nan, 35.  , 28.  ,   nan,  4.  , 74.  ,  9.  , 16.  , 44.  ,\n",
       "       18.  , 45.  , 51.  , 24.  ,   nan, 41.  , 21.  , 48.  ,   nan,\n",
       "       24.  , 42.  , 27.  , 31.  ,   nan,  4.  , 26.  , 47.  , 33.  ,\n",
       "       47.  , 28.  , 15.  , 20.  , 19.  ,   nan, 56.  , 25.  , 33.  ,\n",
       "       22.  , 28.  , 25.  , 39.  , 27.  , 19.  ,   nan, 26.  , 32.  ])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.loc[:,\"Age\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "fixed-radio",
   "metadata": {},
   "outputs": [],
   "source": [
    "Age = data.loc[:,\"Age\"].values.reshape(-1,1) #sklearn当中特征矩阵必须是二维"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "continent-brain",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(891, 1)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Age.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "lucky-piano",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "imp_mean = SimpleImputer()  #实例化，默认均值填补\n",
    "imp_median = SimpleImputer(strategy=\"median\") #用中位数填补\n",
    "imp_0 = SimpleImputer(strategy=\"constant\",fill_value=0) #用0填补"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "controlling-tribune",
   "metadata": {},
   "outputs": [],
   "source": [
    "imp_mean = imp_mean.fit_transform(Age)   #fit_transform一步完成调取结果\n",
    "imp_median = imp_median.fit_transform(Age)\n",
    "imp_0 = imp_0.fit_transform(Age)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "statutory-manner",
   "metadata": {},
   "outputs": [],
   "source": [
    "#在这里我们使用中位数填补Age\n",
    "data.loc[:,\"Age\"] = imp_median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "irish-warrant",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 891 entries, 0 to 890\n",
      "Data columns (total 4 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   Age       891 non-null    float64\n",
      " 1   Sex       891 non-null    object \n",
      " 2   Embarked  889 non-null    object \n",
      " 3   Survived  891 non-null    object \n",
      "dtypes: float64(1), object(3)\n",
      "memory usage: 34.8+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "controversial-opening",
   "metadata": {},
   "outputs": [],
   "source": [
    "#使用众数填补Embarked\n",
    "Embarked = data.loc[:,\"Embarked\"].values.reshape(-1,1)\n",
    "imp_mode = SimpleImputer(strategy = \"most_frequent\")\n",
    "data.loc[:,\"Embarked\"] = imp_mode.fit_transform(Embarked)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "current-favorite",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 891 entries, 0 to 890\n",
      "Data columns (total 4 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   Age       891 non-null    float64\n",
      " 1   Sex       891 non-null    object \n",
      " 2   Embarked  891 non-null    object \n",
      " 3   Survived  891 non-null    object \n",
      "dtypes: float64(1), object(3)\n",
      "memory usage: 34.8+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "integrated-portrait",
   "metadata": {},
   "source": [
    "**用pandas进行处理：**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "strong-employer",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22.0</td>\n",
       "      <td>male</td>\n",
       "      <td>S</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38.0</td>\n",
       "      <td>female</td>\n",
       "      <td>C</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>26.0</td>\n",
       "      <td>female</td>\n",
       "      <td>S</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>35.0</td>\n",
       "      <td>female</td>\n",
       "      <td>S</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>35.0</td>\n",
       "      <td>male</td>\n",
       "      <td>S</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Age     Sex Embarked Survived\n",
       "0  22.0    male        S       No\n",
       "1  38.0  female        C      Yes\n",
       "2  26.0  female        S      Yes\n",
       "3  35.0  female        S      Yes\n",
       "4  35.0    male        S       No"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data_ = pd.read_csv(\"./datasets/Narrativedata.csv\",index_col=0)\n",
    "data_.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "adjustable-volunteer",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 891 entries, 0 to 890\n",
      "Data columns (total 4 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   Age       714 non-null    float64\n",
      " 1   Sex       891 non-null    object \n",
      " 2   Embarked  889 non-null    object \n",
      " 3   Survived  891 non-null    object \n",
      "dtypes: float64(1), object(3)\n",
      "memory usage: 34.8+ KB\n"
     ]
    }
   ],
   "source": [
    "data_.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "consistent-processor",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_.loc[:,\"Age\"] = data_.loc[:,\"Age\"].fillna(data_.loc[:,\"Age\"].median())\n",
    "#.fillna 在DataFrame里面直接进行填补"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "optional-daniel",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 891 entries, 0 to 890\n",
      "Data columns (total 4 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   Age       891 non-null    float64\n",
      " 1   Sex       891 non-null    object \n",
      " 2   Embarked  889 non-null    object \n",
      " 3   Survived  891 non-null    object \n",
      "dtypes: float64(1), object(3)\n",
      "memory usage: 34.8+ KB\n"
     ]
    }
   ],
   "source": [
    "data_.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "treated-court",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_.dropna(axis=0,inplace=True)\n",
    "#.dropna(axis=0)删除所有有缺失值的行，.dropna(axis=1)删除所有有缺失值的列\n",
    "#参数inplace，为True表示在原数据集上进行修改，为False表示生成一个复制对象，不修改原数据，默认False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "thrown-richardson",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 889 entries, 0 to 890\n",
      "Data columns (total 4 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   Age       889 non-null    float64\n",
      " 1   Sex       889 non-null    object \n",
      " 2   Embarked  889 non-null    object \n",
      " 3   Survived  889 non-null    object \n",
      "dtypes: float64(1), object(3)\n",
      "memory usage: 34.7+ KB\n"
     ]
    }
   ],
   "source": [
    "data_.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "streaming-vacation",
   "metadata": {},
   "source": [
    "### 2.3 处理分类型特征：编码与哑变量"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mathematical-gothic",
   "metadata": {},
   "source": [
    "在机器学习中，大多数算法，譬如逻辑回归，支持向量机SVM，k近邻算法等都只能够处理数值型数据，不能处理文字，在sklearn当中，除了专用来处理文字的算法，其他算法在fit的时候全部要求输入数组或矩阵，也不能够导入文字型数据（其实手写决策树和普斯贝叶斯可以处理文字，但是sklearn中规定必须导入数值型）。然而在现实中，许多标签和特征在数据收集完毕的时候，都不是以数字来表现的。比如说，学历的取值可以是[\"小学\"，“初中”，“高中”，\"大学\"]，付费方式可能包含[\"支付宝\"，“现金”，“微信”]等等。在这种情况下，为了让数据适应算法和库，我们必须将数据进行**编码**，即是说，**将文字型数据转换为数值型**。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "virgin-medicaid",
   "metadata": {},
   "source": [
    "- **preprocessing.LabelEncoder：标签专用，能够将分类转换为分类数值**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "essential-kelly",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "y = data.iloc[:,-1]    #要输入的是标签，不是特征矩阵，所以允许一维"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "animal-empire",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       No\n",
       "1      Yes\n",
       "2      Yes\n",
       "3      Yes\n",
       "4       No\n",
       "      ... \n",
       "886     No\n",
       "887    Yes\n",
       "888     No\n",
       "889    Yes\n",
       "890     No\n",
       "Name: Survived, Length: 891, dtype: object"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "baking-stockholm",
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()      #实例化\n",
    "le = le.fit(y)           #导入数据\n",
    "label = le.transform(y)  #transform接口调取结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "destroyed-venice",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1,\n",
       "       1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1,\n",
       "       1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1,\n",
       "       1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0,\n",
       "       1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0,\n",
       "       0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0,\n",
       "       0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0,\n",
       "       1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0,\n",
       "       1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1,\n",
       "       0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0,\n",
       "       0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0,\n",
       "       1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1,\n",
       "       0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1,\n",
       "       1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0,\n",
       "       0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0,\n",
       "       0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0,\n",
       "       0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0,\n",
       "       1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1,\n",
       "       1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
       "       1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0,\n",
       "       0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1,\n",
       "       1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1,\n",
       "       1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0,\n",
       "       0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1,\n",
       "       0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0,\n",
       "       0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "       1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1,\n",
       "       0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0,\n",
       "       0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0,\n",
       "       1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1,\n",
       "       0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0,\n",
       "       0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1,\n",
       "       0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1,\n",
       "       1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1,\n",
       "       1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label #查看获取的结果label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "worse-nothing",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['No', 'Yes'], dtype=object)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le.classes_   #属性.classes_查看标签中究竟有多少类别            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stable-claim",
   "metadata": {},
   "outputs": [],
   "source": [
    "le.fit_transform(y)      #也可以直接fit_transform一步到位\n",
    "\n",
    "le.inverse_transform(label) #使用inverse_transform可以逆转"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "mobile-graphic",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.iloc[:,-1] = label  #让标签等于我们运行出来的结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dimensional-banner",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22.0</td>\n",
       "      <td>male</td>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38.0</td>\n",
       "      <td>female</td>\n",
       "      <td>C</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>26.0</td>\n",
       "      <td>female</td>\n",
       "      <td>S</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>35.0</td>\n",
       "      <td>female</td>\n",
       "      <td>S</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>35.0</td>\n",
       "      <td>male</td>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Age     Sex Embarked  Survived\n",
       "0  22.0    male        S         0\n",
       "1  38.0  female        C         1\n",
       "2  26.0  female        S         1\n",
       "3  35.0  female        S         1\n",
       "4  35.0    male        S         0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sapphire-desperate",
   "metadata": {},
   "outputs": [],
   "source": [
    "#如果不需要教学展示的话我会这么写：\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "data.iloc[:,-1] = LabelEncoder().fit_transform(data.iloc[:,-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "desirable-letter",
   "metadata": {},
   "source": [
    "- **preprocessing.OrdinalEncoder：特征专用，能够将分类特征转换为分类数值**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "august-fairy",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OrdinalEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "average-checklist",
   "metadata": {},
   "outputs": [],
   "source": [
    "#接口categories_对应LabelEncoder的接口classes_，一模一样的功能\n",
    "data2 = data_.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "twenty-cannon",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22.0</td>\n",
       "      <td>male</td>\n",
       "      <td>S</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38.0</td>\n",
       "      <td>female</td>\n",
       "      <td>C</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>26.0</td>\n",
       "      <td>female</td>\n",
       "      <td>S</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>35.0</td>\n",
       "      <td>female</td>\n",
       "      <td>S</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>35.0</td>\n",
       "      <td>male</td>\n",
       "      <td>S</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Age     Sex Embarked Survived\n",
       "0  22.0    male        S       No\n",
       "1  38.0  female        C      Yes\n",
       "2  26.0  female        S      Yes\n",
       "3  35.0  female        S      Yes\n",
       "4  35.0    male        S       No"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "major-touch",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "data2.iloc[:,-1] = LabelEncoder().fit_transform(data2.iloc[:,-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "aquatic-beaver",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array(['female', 'male'], dtype=object), array(['C', 'Q', 'S'], dtype=object)]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "OrdinalEncoder().fit(data2.iloc[:,1:-1]).categories_ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "private-crown",
   "metadata": {},
   "outputs": [],
   "source": [
    "data2.iloc[:,1:-1] = OrdinalEncoder().fit_transform(data2.iloc[:,1:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "herbal-bridges",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>26.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>35.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>35.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Age  Sex  Embarked  Survived\n",
       "0  22.0  1.0       2.0         0\n",
       "1  38.0  0.0       0.0         1\n",
       "2  26.0  0.0       2.0         1\n",
       "3  35.0  0.0       2.0         1\n",
       "4  35.0  1.0       2.0         0"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "smoking-australian",
   "metadata": {},
   "source": [
    "- **preprocessing.OneHotEncoder：独热编码，创建哑变量**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "entertaining-running",
   "metadata": {},
   "source": [
    "我们刚才已经用OrdinalEncoder把分类变量Sex和Embarked都转换成数字对应的类别了。在舱门Embarked这一列中，我们使用[0,1,2]代表了三个不同的舱门，然而这种转换是正确的吗？<br>\n",
    "<br>\n",
    "我们来思考三种不同性质的分类数据：<br>\n",
    "<br>\n",
    "1） 舱门（S，C，Q）<br>\n",
    "<br>\n",
    "三种取值S，C，Q是相互独立的，彼此之间完全没有联系，表达的是S≠C≠Q的概念。这是名义变量。<br>\n",
    "<br>\n",
    "2） 学历（小学，初中，高中）<br>\n",
    "<br>\n",
    "三种取值不是完全独立的，我们可以明显看出，在性质上可以有高中>初中>小学这样的联系，学历有高低，但是学历取值之间却不是可以计算的，我们不能说小学 + 某个取值 = 初中。这是有序变量。<br>\n",
    "<br>\n",
    "3） 体重（>45kg，>90kg，>135kg）<br>\n",
    "<br>\n",
    "各个取值之间有联系，且是可以互相计算的，比如120kg - 45kg = 90kg，分类之间可以通过数学计算互相转换。这是有距变量。<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "black-regression",
   "metadata": {},
   "source": [
    "然而在对特征进行编码的时候，这三种分类数据都会被我们转换为[0,1,2]，这三个数字在算法看来，是连续且可以计算的，这三个数字相互不等，有大小，并且有着可以相加相乘的联系。所以算法会把舱门，学历这样的分类特征，都误会成是体重这样的分类特征。这是说，我们把分类转换成数字的时候，忽略了数字中自带的数学性质，所以给算法传达了一些不准确的信息，而这会影响我们的建模。<br>\n",
    "<br>\n",
    "类别OrdinalEncoder可以用来处理有序变量，但对于名义变量，我们只有使用哑变量的方式来处理，才能够尽量向算法传达最准确的信息： "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "sharp-surrey",
   "metadata": {},
   "source": [
    "![image.png](https://pic1.zhimg.com/80/v2-99f178996727bba0fd5fcf36d7a67874_720w.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "biblical-acrobat",
   "metadata": {},
   "source": [
    "这样的变化，让算法能够彻底领悟，原来三个取值是没有可计算性质的，是“有你就没有我”的不等概念。在我们的数据中，性别和舱门，都是这样的名义变量。因此我们需要使用独热编码，将两个特征都转换为哑变量。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "balanced-resort",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22.0</td>\n",
       "      <td>male</td>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38.0</td>\n",
       "      <td>female</td>\n",
       "      <td>C</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>26.0</td>\n",
       "      <td>female</td>\n",
       "      <td>S</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>35.0</td>\n",
       "      <td>female</td>\n",
       "      <td>S</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>35.0</td>\n",
       "      <td>male</td>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Age     Sex Embarked  Survived\n",
       "0  22.0    male        S         0\n",
       "1  38.0  female        C         1\n",
       "2  26.0  female        S         1\n",
       "3  35.0  female        S         1\n",
       "4  35.0    male        S         0"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "north-drama",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "X = data.iloc[:,1:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "textile-robertson",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sex</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>male</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>female</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>female</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>female</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>male</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>male</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>female</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>female</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>male</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>male</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>891 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Sex Embarked\n",
       "0      male        S\n",
       "1    female        C\n",
       "2    female        S\n",
       "3    female        S\n",
       "4      male        S\n",
       "..      ...      ...\n",
       "886    male        S\n",
       "887  female        S\n",
       "888  female        S\n",
       "889    male        C\n",
       "890    male        Q\n",
       "\n",
       "[891 rows x 2 columns]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "requested-spectacular",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1., 0., 0., 1., 0.],\n",
       "       [1., 0., 1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 1., 0.],\n",
       "       ...,\n",
       "       [1., 0., 0., 0., 1., 0.],\n",
       "       [0., 1., 1., 0., 0., 0.],\n",
       "       [0., 1., 0., 1., 0., 0.]])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc = OneHotEncoder(categories='auto').fit(X)\n",
    "result = enc.transform(X).toarray()\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "overall-whole",
   "metadata": {},
   "outputs": [],
   "source": [
    "#依然可以直接一步到位，但为了给大家展示模型属性，所以还是写成了三步\n",
    "OneHotEncoder(categories='auto').fit_transform(X).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "romance-nerve",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>male</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>female</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>female</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>female</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>male</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>male</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>female</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>female</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>male</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>male</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>891 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0  1\n",
       "0      male  S\n",
       "1    female  C\n",
       "2    female  S\n",
       "3    female  S\n",
       "4      male  S\n",
       "..      ... ..\n",
       "886    male  S\n",
       "887  female  S\n",
       "888  female  S\n",
       "889    male  C\n",
       "890    male  Q\n",
       "\n",
       "[891 rows x 2 columns]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#依然可以还原\n",
    "pd.DataFrame(enc.inverse_transform(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "accomplished-filename",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['x0_female', 'x0_male', 'x1_C', 'x1_Q', 'x1_S', 'x1_nan'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "cathedral-airfare",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(891, 6)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "official-ticket",
   "metadata": {},
   "outputs": [],
   "source": [
    "#axis=1,表示跨行进行合并，也就是将两个表左右相连，如果是axis=0，就是将两个表上下相连\n",
    "newdata = pd.concat([data,pd.DataFrame(result)],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "cleared-seating",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Survived</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22.0</td>\n",
       "      <td>male</td>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38.0</td>\n",
       "      <td>female</td>\n",
       "      <td>C</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>26.0</td>\n",
       "      <td>female</td>\n",
       "      <td>S</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>35.0</td>\n",
       "      <td>female</td>\n",
       "      <td>S</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>35.0</td>\n",
       "      <td>male</td>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Age     Sex Embarked  Survived    0    1    2    3    4    5\n",
       "0  22.0    male        S         0  0.0  1.0  0.0  0.0  1.0  0.0\n",
       "1  38.0  female        C         1  1.0  0.0  1.0  0.0  0.0  0.0\n",
       "2  26.0  female        S         1  1.0  0.0  0.0  0.0  1.0  0.0\n",
       "3  35.0  female        S         1  1.0  0.0  0.0  0.0  1.0  0.0\n",
       "4  35.0    male        S         0  0.0  1.0  0.0  0.0  1.0  0.0"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newdata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "solved-penny",
   "metadata": {},
   "outputs": [],
   "source": [
    "newdata.drop([\"Sex\",\"Embarked\"],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "dying-gardening",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Survived</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>26.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Age  Survived    0    1    2    3    4    5\n",
       "0  22.0         0  0.0  1.0  0.0  0.0  1.0  0.0\n",
       "1  38.0         1  1.0  0.0  1.0  0.0  0.0  0.0\n",
       "2  26.0         1  1.0  0.0  0.0  0.0  1.0  0.0\n",
       "3  35.0         1  1.0  0.0  0.0  0.0  1.0  0.0\n",
       "4  35.0         0  0.0  1.0  0.0  0.0  1.0  0.0"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newdata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "induced-column",
   "metadata": {},
   "outputs": [],
   "source": [
    "newdata.columns = [\"Age\",\"Survived\",\"Female\",\"Male\",\"Embarked_C\",\"Embarked_Q\",\"Embarked_S\",\"Embarked_NAN\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "fitting-needle",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Female</th>\n",
       "      <th>Male</th>\n",
       "      <th>Embarked_C</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "      <th>Embarked_NAN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>26.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Age  Survived  Female  Male  Embarked_C  Embarked_Q  Embarked_S  \\\n",
       "0  22.0         0     0.0   1.0         0.0         0.0         1.0   \n",
       "1  38.0         1     1.0   0.0         1.0         0.0         0.0   \n",
       "2  26.0         1     1.0   0.0         0.0         0.0         1.0   \n",
       "3  35.0         1     1.0   0.0         0.0         0.0         1.0   \n",
       "4  35.0         0     0.0   1.0         0.0         0.0         1.0   \n",
       "\n",
       "   Embarked_NAN  \n",
       "0           0.0  \n",
       "1           0.0  \n",
       "2           0.0  \n",
       "3           0.0  \n",
       "4           0.0  "
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newdata.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "demanding-powell",
   "metadata": {},
   "source": [
    "特征可以做哑变量，标签也可以吗？可以，使用类sklearn.preprocessing.LabelBinarizer可以对做哑变量，许多算法都可以处理多标签问题（比如说决策树），但是这样的做法在现实中不常见，因此我们在这里就不赘述了。"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "primary-fence",
   "metadata": {},
   "source": [
    "![image.png](https://pic3.zhimg.com/80/v2-51212eeabf315c53666bf0f4c601b39a_720w.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daily-surge",
   "metadata": {},
   "source": [
    "### 2.4 处理连续型特征：二值化与分段"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "amino-quantity",
   "metadata": {},
   "source": [
    "- **sklearn.preprocessing.Binarizer**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "applied-ballot",
   "metadata": {},
   "source": [
    "根据阈值将数据二值化（将特征值设置为0或1），用于处理连续型变量。大于阈值的值映射为1，而小于或等于阈值的值映射为0。默认阈值为0时，特征中所有的正值都映射到1。二值化是对文本计数数据的常见操作，分析人员可以决定仅考虑某种现象的存在与否。它还可以用作考虑布尔随机变量的估计器的预处理步骤（例如，使用贝叶斯设置中的伯努利分布建模）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "aerial-annex",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22.0</td>\n",
       "      <td>male</td>\n",
       "      <td>S</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38.0</td>\n",
       "      <td>female</td>\n",
       "      <td>C</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>26.0</td>\n",
       "      <td>female</td>\n",
       "      <td>S</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>35.0</td>\n",
       "      <td>female</td>\n",
       "      <td>S</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>35.0</td>\n",
       "      <td>male</td>\n",
       "      <td>S</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Age     Sex Embarked Survived\n",
       "0  22.0    male        S       No\n",
       "1  38.0  female        C      Yes\n",
       "2  26.0  female        S      Yes\n",
       "3  35.0  female        S      Yes\n",
       "4  35.0    male        S       No"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "temporal-safety",
   "metadata": {},
   "outputs": [],
   "source": [
    "#将年龄二值化\n",
    "\n",
    "data_2 = data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "early-remainder",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import Binarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "controlled-memphis",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data_2.iloc[:,0].values.reshape(-1,1)#类为特征专用，所以不能使用一维数组"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "upper-gospel",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[22.  ],\n",
       "       [38.  ],\n",
       "       [26.  ],\n",
       "       [35.  ],\n",
       "       [35.  ],\n",
       "       [  nan],\n",
       "       [54.  ],\n",
       "       [ 2.  ],\n",
       "       [27.  ],\n",
       "       [14.  ],\n",
       "       [ 4.  ],\n",
       "       [58.  ],\n",
       "       [20.  ],\n",
       "       [39.  ],\n",
       "       [14.  ],\n",
       "       [55.  ],\n",
       "       [ 2.  ],\n",
       "       [  nan],\n",
       "       [31.  ],\n",
       "       [  nan],\n",
       "       [35.  ],\n",
       "       [34.  ],\n",
       "       [15.  ],\n",
       "       [28.  ],\n",
       "       [ 8.  ],\n",
       "       [38.  ],\n",
       "       [  nan],\n",
       "       [19.  ],\n",
       "       [  nan],\n",
       "       [  nan],\n",
       "       [40.  ],\n",
       "       [  nan],\n",
       "       [  nan],\n",
       "       [66.  ],\n",
       "       [28.  ],\n",
       "       [42.  ],\n",
       "       [  nan],\n",
       "       [21.  ],\n",
       "       [18.  ],\n",
       "       [14.  ],\n",
       "       [40.  ],\n",
       "       [27.  ],\n",
       "       [  nan],\n",
       "       [ 3.  ],\n",
       "       [19.  ],\n",
       "       [  nan],\n",
       "       [  nan],\n",
       "       [  nan],\n",
       "       [  nan],\n",
       "       [18.  ],\n",
       "       [ 7.  ],\n",
       "       [21.  ],\n",
       "       [49.  ],\n",
       "       [29.  ],\n",
       "       [65.  ],\n",
       "       [  nan],\n",
       "       [21.  ],\n",
       "       [28.5 ],\n",
       "       [ 5.  ],\n",
       "       [11.  ],\n",
       "       [22.  ],\n",
       "       [38.  ],\n",
       "       [45.  ],\n",
       "       [ 4.  ],\n",
       "       [  nan],\n",
       "       [  nan],\n",
       "       [29.  ],\n",
       "       [19.  ],\n",
       "       [17.  ],\n",
       "       [26.  ],\n",
       "       [32.  ],\n",
       "       [16.  ],\n",
       "       [21.  ],\n",
       "       [26.  ],\n",
       "       [32.  ],\n",
       "       [25.  ],\n",
       "       [  nan],\n",
       "       [  nan],\n",
       "       [ 0.83],\n",
       "       [30.  ],\n",
       "       [22.  ],\n",
       "       [29.  ],\n",
       "       [  nan],\n",
       "       [28.  ],\n",
       "       [17.  ],\n",
       "       [33.  ],\n",
       "       [16.  ],\n",
       "       [  nan],\n",
       "       [23.  ],\n",
       "       [24.  ],\n",
       "       [29.  ],\n",
       "       [20.  ],\n",
       "       [46.  ],\n",
       "       [26.  ],\n",
       "       [59.  ],\n",
       "       [  nan],\n",
       "       [71.  ],\n",
       "       [23.  ],\n",
       "       [34.  ],\n",
       "       [34.  ],\n",
       "       [28.  ],\n",
       "       [  nan],\n",
       "       [21.  ],\n",
       "       [33.  ],\n",
       "       [37.  ],\n",
       "       [28.  ],\n",
       "       [21.  ],\n",
       "       [  nan],\n",
       "       [38.  ],\n",
       "       [  nan],\n",
       "       [47.  ],\n",
       "       [14.5 ],\n",
       "       [22.  ],\n",
       "       [20.  ],\n",
       "       [17.  ],\n",
       "       [21.  ],\n",
       "       [70.5 ],\n",
       "       [29.  ],\n",
       "       [24.  ],\n",
       "       [ 2.  ],\n",
       "       [21.  ],\n",
       "       [  nan],\n",
       "       [32.5 ],\n",
       "       [32.5 ],\n",
       "       [54.  ],\n",
       "       [12.  ],\n",
       "       [  nan],\n",
       "       [24.  ],\n",
       "       [  nan],\n",
       "       [45.  ],\n",
       "       [33.  ],\n",
       "       [20.  ],\n",
       "       [47.  ],\n",
       "       [29.  ],\n",
       "       [25.  ],\n",
       "       [23.  ],\n",
       "       [19.  ],\n",
       "       [37.  ],\n",
       "       [16.  ],\n",
       "       [24.  ],\n",
       "       [  nan],\n",
       "       [22.  ],\n",
       "       [24.  ],\n",
       "       [19.  ],\n",
       "       [18.  ],\n",
       "       [19.  ],\n",
       "       [27.  ],\n",
       "       [ 9.  ],\n",
       "       [36.5 ],\n",
       "       [42.  ],\n",
       "       [51.  ],\n",
       "       [22.  ],\n",
       "       [55.5 ],\n",
       "       [40.5 ],\n",
       "       [  nan],\n",
       "       [51.  ],\n",
       "       [16.  ],\n",
       "       [30.  ],\n",
       "       [  nan],\n",
       "       [  nan],\n",
       "       [44.  ],\n",
       "       [40.  ],\n",
       "       [26.  ],\n",
       "       [17.  ],\n",
       "       [ 1.  ],\n",
       "       [ 9.  ],\n",
       "       [  nan],\n",
       "       [45.  ],\n",
       "       [  nan],\n",
       "       [28.  ],\n",
       "       [61.  ],\n",
       "       [ 4.  ],\n",
       "       [ 1.  ],\n",
       "       [21.  ],\n",
       "       [56.  ],\n",
       "       [18.  ],\n",
       "       [  nan],\n",
       "       [50.  ],\n",
       "       [30.  ],\n",
       "       [36.  ],\n",
       "       [  nan],\n",
       "       [  nan],\n",
       "       [ 9.  ],\n",
       "       [ 1.  ],\n",
       "       [ 4.  ],\n",
       "       [  nan],\n",
       "       [  nan],\n",
       "       [45.  ],\n",
       "       [40.  ],\n",
       "       [36.  ],\n",
       "       [32.  ],\n",
       "       [19.  ],\n",
       "       [19.  ],\n",
       "       [ 3.  ],\n",
       "       [44.  ],\n",
       "       [58.  ],\n",
       "       [  nan],\n",
       "       [42.  ],\n",
       "       [  nan],\n",
       "       [24.  ],\n",
       "       [28.  ],\n",
       "       [  nan],\n",
       "       [34.  ],\n",
       "       [45.5 ],\n",
       "       [18.  ],\n",
       "       [ 2.  ],\n",
       "       [32.  ],\n",
       "       [26.  ],\n",
       "       [16.  ],\n",
       "       [40.  ],\n",
       "       [24.  ],\n",
       "       [35.  ],\n",
       "       [22.  ],\n",
       "       [30.  ],\n",
       "       [  nan],\n",
       "       [31.  ],\n",
       "       [27.  ],\n",
       "       [42.  ],\n",
       "       [32.  ],\n",
       "       [30.  ],\n",
       "       [16.  ],\n",
       "       [27.  ],\n",
       "       [51.  ],\n",
       "       [  nan],\n",
       "       [38.  ],\n",
       "       [22.  ],\n",
       "       [19.  ],\n",
       "       [20.5 ],\n",
       "       [18.  ],\n",
       "       [  nan],\n",
       "       [35.  ],\n",
       "       [29.  ],\n",
       "       [59.  ],\n",
       "       [ 5.  ],\n",
       "       [24.  ],\n",
       "       [  nan],\n",
       "       [44.  ],\n",
       "       [ 8.  ],\n",
       "       [19.  ],\n",
       "       [33.  ],\n",
       "       [  nan],\n",
       "       [  nan],\n",
       "       [29.  ],\n",
       "       [22.  ],\n",
       "       [30.  ],\n",
       "       [44.  ],\n",
       "       [25.  ],\n",
       "       [24.  ],\n",
       "       [37.  ],\n",
       "       [54.  ],\n",
       "       [  nan],\n",
       "       [29.  ],\n",
       "       [62.  ],\n",
       "       [30.  ],\n",
       "       [41.  ],\n",
       "       [29.  ],\n",
       "       [  nan],\n",
       "       [30.  ],\n",
       "       [35.  ],\n",
       "       [50.  ],\n",
       "       [  nan],\n",
       "       [ 3.  ],\n",
       "       [52.  ],\n",
       "       [40.  ],\n",
       "       [  nan],\n",
       "       [36.  ],\n",
       "       [16.  ],\n",
       "       [25.  ],\n",
       "       [58.  ],\n",
       "       [35.  ],\n",
       "       [  nan],\n",
       "       [25.  ],\n",
       "       [41.  ],\n",
       "       [37.  ],\n",
       "       [  nan],\n",
       "       [63.  ],\n",
       "       [45.  ],\n",
       "       [  nan],\n",
       "       [ 7.  ],\n",
       "       [35.  ],\n",
       "       [65.  ],\n",
       "       [28.  ],\n",
       "       [16.  ],\n",
       "       [19.  ],\n",
       "       [  nan],\n",
       "       [33.  ],\n",
       "       [30.  ],\n",
       "       [22.  ],\n",
       "       [42.  ],\n",
       "       [22.  ],\n",
       "       [26.  ],\n",
       "       [19.  ],\n",
       "       [36.  ],\n",
       "       [24.  ],\n",
       "       [24.  ],\n",
       "       [  nan],\n",
       "       [23.5 ],\n",
       "       [ 2.  ],\n",
       "       [  nan],\n",
       "       [50.  ],\n",
       "       [  nan],\n",
       "       [  nan],\n",
       "       [19.  ],\n",
       "       [  nan],\n",
       "       [  nan],\n",
       "       [ 0.92],\n",
       "       [  nan],\n",
       "       [17.  ],\n",
       "       [30.  ],\n",
       "       [30.  ],\n",
       "       [24.  ],\n",
       "       [18.  ],\n",
       "       [26.  ],\n",
       "       [28.  ],\n",
       "       [43.  ],\n",
       "       [26.  ],\n",
       "       [24.  ],\n",
       "       [54.  ],\n",
       "       [31.  ],\n",
       "       [40.  ],\n",
       "       [22.  ],\n",
       "       [27.  ],\n",
       "       [30.  ],\n",
       "       [22.  ],\n",
       "       [  nan],\n",
       "       [36.  ],\n",
       "       [61.  ],\n",
       "       [36.  ],\n",
       "       [31.  ],\n",
       "       [16.  ],\n",
       "       [  nan],\n",
       "       [45.5 ],\n",
       "       [38.  ],\n",
       "       [16.  ],\n",
       "       [  nan],\n",
       "       [  nan],\n",
       "       [29.  ],\n",
       "       [41.  ],\n",
       "       [45.  ],\n",
       "       [45.  ],\n",
       "       [ 2.  ],\n",
       "       [24.  ],\n",
       "       [28.  ],\n",
       "       [25.  ],\n",
       "       [36.  ],\n",
       "       [24.  ],\n",
       "       [40.  ],\n",
       "       [  nan],\n",
       "       [ 3.  ],\n",
       "       [42.  ],\n",
       "       [23.  ],\n",
       "       [  nan],\n",
       "       [15.  ],\n",
       "       [25.  ],\n",
       "       [  nan],\n",
       "       [28.  ],\n",
       "       [22.  ],\n",
       "       [38.  ],\n",
       "       [  nan],\n",
       "       [  nan],\n",
       "       [40.  ],\n",
       "       [29.  ],\n",
       "       [45.  ],\n",
       "       [35.  ],\n",
       "       [  nan],\n",
       "       [30.  ],\n",
       "       [60.  ],\n",
       "       [  nan],\n",
       "       [  nan],\n",
       "       [24.  ],\n",
       "       [25.  ],\n",
       "       [18.  ],\n",
       "       [19.  ],\n",
       "       [22.  ],\n",
       "       [ 3.  ],\n",
       "       [  nan],\n",
       "       [22.  ],\n",
       "       [27.  ],\n",
       "       [20.  ],\n",
       "       [19.  ],\n",
       "       [42.  ],\n",
       "       [ 1.  ],\n",
       "       [32.  ],\n",
       "       [35.  ],\n",
       "       [  nan],\n",
       "       [18.  ],\n",
       "       [ 1.  ],\n",
       "       [36.  ],\n",
       "       [  nan],\n",
       "       [17.  ],\n",
       "       [36.  ],\n",
       "       [21.  ],\n",
       "       [28.  ],\n",
       "       [23.  ],\n",
       "       [24.  ],\n",
       "       [22.  ],\n",
       "       [31.  ],\n",
       "       [46.  ],\n",
       "       [23.  ],\n",
       "       [28.  ],\n",
       "       [39.  ],\n",
       "       [26.  ],\n",
       "       [21.  ],\n",
       "       [28.  ],\n",
       "       [20.  ],\n",
       "       [34.  ],\n",
       "       [51.  ],\n",
       "       [ 3.  ],\n",
       "       [21.  ],\n",
       "       [  nan],\n",
       "       [  nan],\n",
       "       [  nan],\n",
       "       [33.  ],\n",
       "       [  nan],\n",
       "       [44.  ],\n",
       "       [  nan],\n",
       "       [34.  ],\n",
       "       [18.  ],\n",
       "       [30.  ],\n",
       "       [10.  ],\n",
       "       [  nan],\n",
       "       [21.  ],\n",
       "       [29.  ],\n",
       "       [28.  ],\n",
       "       [18.  ],\n",
       "       [  nan],\n",
       "       [28.  ],\n",
       "       [19.  ],\n",
       "       [  nan],\n",
       "       [32.  ],\n",
       "       [28.  ],\n",
       "       [  nan],\n",
       "       [42.  ],\n",
       "       [17.  ],\n",
       "       [50.  ],\n",
       "       [14.  ],\n",
       "       [21.  ],\n",
       "       [24.  ],\n",
       "       [64.  ],\n",
       "       [31.  ],\n",
       "       [45.  ],\n",
       "       [20.  ],\n",
       "       [25.  ],\n",
       "       [28.  ],\n",
       "       [  nan],\n",
       "       [ 4.  ],\n",
       "       [13.  ],\n",
       "       [34.  ],\n",
       "       [ 5.  ],\n",
       "       [52.  ],\n",
       "       [36.  ],\n",
       "       [  nan],\n",
       "       [30.  ],\n",
       "       [49.  ],\n",
       "       [  nan],\n",
       "       [29.  ],\n",
       "       [65.  ],\n",
       "       [  nan],\n",
       "       [50.  ],\n",
       "       [  nan],\n",
       "       [48.  ],\n",
       "       [34.  ],\n",
       "       [47.  ],\n",
       "       [48.  ],\n",
       "       [  nan],\n",
       "       [38.  ],\n",
       "       [  nan],\n",
       "       [56.  ],\n",
       "       [  nan],\n",
       "       [ 0.75],\n",
       "       [  nan],\n",
       "       [38.  ],\n",
       "       [33.  ],\n",
       "       [23.  ],\n",
       "       [22.  ],\n",
       "       [  nan],\n",
       "       [34.  ],\n",
       "       [29.  ],\n",
       "       [22.  ],\n",
       "       [ 2.  ],\n",
       "       [ 9.  ],\n",
       "       [  nan],\n",
       "       [50.  ],\n",
       "       [63.  ],\n",
       "       [25.  ],\n",
       "       [  nan],\n",
       "       [35.  ],\n",
       "       [58.  ],\n",
       "       [30.  ],\n",
       "       [ 9.  ],\n",
       "       [  nan],\n",
       "       [21.  ],\n",
       "       [55.  ],\n",
       "       [71.  ],\n",
       "       [21.  ],\n",
       "       [  nan],\n",
       "       [54.  ],\n",
       "       [  nan],\n",
       "       [25.  ],\n",
       "       [24.  ],\n",
       "       [17.  ],\n",
       "       [21.  ],\n",
       "       [  nan],\n",
       "       [37.  ],\n",
       "       [16.  ],\n",
       "       [18.  ],\n",
       "       [33.  ],\n",
       "       [  nan],\n",
       "       [28.  ],\n",
       "       [26.  ],\n",
       "       [29.  ],\n",
       "       [  nan],\n",
       "       [36.  ],\n",
       "       [54.  ],\n",
       "       [24.  ],\n",
       "       [47.  ],\n",
       "       [34.  ],\n",
       "       [  nan],\n",
       "       [36.  ],\n",
       "       [32.  ],\n",
       "       [30.  ],\n",
       "       [22.  ],\n",
       "       [  nan],\n",
       "       [44.  ],\n",
       "       [  nan],\n",
       "       [40.5 ],\n",
       "       [50.  ],\n",
       "       [  nan],\n",
       "       [39.  ],\n",
       "       [23.  ],\n",
       "       [ 2.  ],\n",
       "       [  nan],\n",
       "       [17.  ],\n",
       "       [  nan],\n",
       "       [30.  ],\n",
       "       [ 7.  ],\n",
       "       [45.  ],\n",
       "       [30.  ],\n",
       "       [  nan],\n",
       "       [22.  ],\n",
       "       [36.  ],\n",
       "       [ 9.  ],\n",
       "       [11.  ],\n",
       "       [32.  ],\n",
       "       [50.  ],\n",
       "       [64.  ],\n",
       "       [19.  ],\n",
       "       [  nan],\n",
       "       [33.  ],\n",
       "       [ 8.  ],\n",
       "       [17.  ],\n",
       "       [27.  ],\n",
       "       [  nan],\n",
       "       [22.  ],\n",
       "       [22.  ],\n",
       "       [62.  ],\n",
       "       [48.  ],\n",
       "       [  nan],\n",
       "       [39.  ],\n",
       "       [36.  ],\n",
       "       [  nan],\n",
       "       [40.  ],\n",
       "       [28.  ],\n",
       "       [  nan],\n",
       "       [  nan],\n",
       "       [24.  ],\n",
       "       [19.  ],\n",
       "       [29.  ],\n",
       "       [  nan],\n",
       "       [32.  ],\n",
       "       [62.  ],\n",
       "       [53.  ],\n",
       "       [36.  ],\n",
       "       [  nan],\n",
       "       [16.  ],\n",
       "       [19.  ],\n",
       "       [34.  ],\n",
       "       [39.  ],\n",
       "       [  nan],\n",
       "       [32.  ],\n",
       "       [25.  ],\n",
       "       [39.  ],\n",
       "       [54.  ],\n",
       "       [36.  ],\n",
       "       [  nan],\n",
       "       [18.  ],\n",
       "       [47.  ],\n",
       "       [60.  ],\n",
       "       [22.  ],\n",
       "       [  nan],\n",
       "       [35.  ],\n",
       "       [52.  ],\n",
       "       [47.  ],\n",
       "       [  nan],\n",
       "       [37.  ],\n",
       "       [36.  ],\n",
       "       [  nan],\n",
       "       [49.  ],\n",
       "       [  nan],\n",
       "       [49.  ],\n",
       "       [24.  ],\n",
       "       [  nan],\n",
       "       [  nan],\n",
       "       [44.  ],\n",
       "       [35.  ],\n",
       "       [36.  ],\n",
       "       [30.  ],\n",
       "       [27.  ],\n",
       "       [22.  ],\n",
       "       [40.  ],\n",
       "       [39.  ],\n",
       "       [  nan],\n",
       "       [  nan],\n",
       "       [  nan],\n",
       "       [35.  ],\n",
       "       [24.  ],\n",
       "       [34.  ],\n",
       "       [26.  ],\n",
       "       [ 4.  ],\n",
       "       [26.  ],\n",
       "       [27.  ],\n",
       "       [42.  ],\n",
       "       [20.  ],\n",
       "       [21.  ],\n",
       "       [21.  ],\n",
       "       [61.  ],\n",
       "       [57.  ],\n",
       "       [21.  ],\n",
       "       [26.  ],\n",
       "       [  nan],\n",
       "       [80.  ],\n",
       "       [51.  ],\n",
       "       [32.  ],\n",
       "       [  nan],\n",
       "       [ 9.  ],\n",
       "       [28.  ],\n",
       "       [32.  ],\n",
       "       [31.  ],\n",
       "       [41.  ],\n",
       "       [  nan],\n",
       "       [20.  ],\n",
       "       [24.  ],\n",
       "       [ 2.  ],\n",
       "       [  nan],\n",
       "       [ 0.75],\n",
       "       [48.  ],\n",
       "       [19.  ],\n",
       "       [56.  ],\n",
       "       [  nan],\n",
       "       [23.  ],\n",
       "       [  nan],\n",
       "       [18.  ],\n",
       "       [21.  ],\n",
       "       [  nan],\n",
       "       [18.  ],\n",
       "       [24.  ],\n",
       "       [  nan],\n",
       "       [32.  ],\n",
       "       [23.  ],\n",
       "       [58.  ],\n",
       "       [50.  ],\n",
       "       [40.  ],\n",
       "       [47.  ],\n",
       "       [36.  ],\n",
       "       [20.  ],\n",
       "       [32.  ],\n",
       "       [25.  ],\n",
       "       [  nan],\n",
       "       [43.  ],\n",
       "       [  nan],\n",
       "       [40.  ],\n",
       "       [31.  ],\n",
       "       [70.  ],\n",
       "       [31.  ],\n",
       "       [  nan],\n",
       "       [18.  ],\n",
       "       [24.5 ],\n",
       "       [18.  ],\n",
       "       [43.  ],\n",
       "       [36.  ],\n",
       "       [  nan],\n",
       "       [27.  ],\n",
       "       [20.  ],\n",
       "       [14.  ],\n",
       "       [60.  ],\n",
       "       [25.  ],\n",
       "       [14.  ],\n",
       "       [19.  ],\n",
       "       [18.  ],\n",
       "       [15.  ],\n",
       "       [31.  ],\n",
       "       [ 4.  ],\n",
       "       [  nan],\n",
       "       [25.  ],\n",
       "       [60.  ],\n",
       "       [52.  ],\n",
       "       [44.  ],\n",
       "       [  nan],\n",
       "       [49.  ],\n",
       "       [42.  ],\n",
       "       [18.  ],\n",
       "       [35.  ],\n",
       "       [18.  ],\n",
       "       [25.  ],\n",
       "       [26.  ],\n",
       "       [39.  ],\n",
       "       [45.  ],\n",
       "       [42.  ],\n",
       "       [22.  ],\n",
       "       [  nan],\n",
       "       [24.  ],\n",
       "       [  nan],\n",
       "       [48.  ],\n",
       "       [29.  ],\n",
       "       [52.  ],\n",
       "       [19.  ],\n",
       "       [38.  ],\n",
       "       [27.  ],\n",
       "       [  nan],\n",
       "       [33.  ],\n",
       "       [ 6.  ],\n",
       "       [17.  ],\n",
       "       [34.  ],\n",
       "       [50.  ],\n",
       "       [27.  ],\n",
       "       [20.  ],\n",
       "       [30.  ],\n",
       "       [  nan],\n",
       "       [25.  ],\n",
       "       [25.  ],\n",
       "       [29.  ],\n",
       "       [11.  ],\n",
       "       [  nan],\n",
       "       [23.  ],\n",
       "       [23.  ],\n",
       "       [28.5 ],\n",
       "       [48.  ],\n",
       "       [35.  ],\n",
       "       [  nan],\n",
       "       [  nan],\n",
       "       [  nan],\n",
       "       [36.  ],\n",
       "       [21.  ],\n",
       "       [24.  ],\n",
       "       [31.  ],\n",
       "       [70.  ],\n",
       "       [16.  ],\n",
       "       [30.  ],\n",
       "       [19.  ],\n",
       "       [31.  ],\n",
       "       [ 4.  ],\n",
       "       [ 6.  ],\n",
       "       [33.  ],\n",
       "       [23.  ],\n",
       "       [48.  ],\n",
       "       [ 0.67],\n",
       "       [28.  ],\n",
       "       [18.  ],\n",
       "       [34.  ],\n",
       "       [33.  ],\n",
       "       [  nan],\n",
       "       [41.  ],\n",
       "       [20.  ],\n",
       "       [36.  ],\n",
       "       [16.  ],\n",
       "       [51.  ],\n",
       "       [  nan],\n",
       "       [30.5 ],\n",
       "       [  nan],\n",
       "       [32.  ],\n",
       "       [24.  ],\n",
       "       [48.  ],\n",
       "       [57.  ],\n",
       "       [  nan],\n",
       "       [54.  ],\n",
       "       [18.  ],\n",
       "       [  nan],\n",
       "       [ 5.  ],\n",
       "       [  nan],\n",
       "       [43.  ],\n",
       "       [13.  ],\n",
       "       [17.  ],\n",
       "       [29.  ],\n",
       "       [  nan],\n",
       "       [25.  ],\n",
       "       [25.  ],\n",
       "       [18.  ],\n",
       "       [ 8.  ],\n",
       "       [ 1.  ],\n",
       "       [46.  ],\n",
       "       [  nan],\n",
       "       [16.  ],\n",
       "       [  nan],\n",
       "       [  nan],\n",
       "       [25.  ],\n",
       "       [39.  ],\n",
       "       [49.  ],\n",
       "       [31.  ],\n",
       "       [30.  ],\n",
       "       [30.  ],\n",
       "       [34.  ],\n",
       "       [31.  ],\n",
       "       [11.  ],\n",
       "       [ 0.42],\n",
       "       [27.  ],\n",
       "       [31.  ],\n",
       "       [39.  ],\n",
       "       [18.  ],\n",
       "       [39.  ],\n",
       "       [33.  ],\n",
       "       [26.  ],\n",
       "       [39.  ],\n",
       "       [35.  ],\n",
       "       [ 6.  ],\n",
       "       [30.5 ],\n",
       "       [  nan],\n",
       "       [23.  ],\n",
       "       [31.  ],\n",
       "       [43.  ],\n",
       "       [10.  ],\n",
       "       [52.  ],\n",
       "       [27.  ],\n",
       "       [38.  ],\n",
       "       [27.  ],\n",
       "       [ 2.  ],\n",
       "       [  nan],\n",
       "       [  nan],\n",
       "       [ 1.  ],\n",
       "       [  nan],\n",
       "       [62.  ],\n",
       "       [15.  ],\n",
       "       [ 0.83],\n",
       "       [  nan],\n",
       "       [23.  ],\n",
       "       [18.  ],\n",
       "       [39.  ],\n",
       "       [21.  ],\n",
       "       [  nan],\n",
       "       [32.  ],\n",
       "       [  nan],\n",
       "       [20.  ],\n",
       "       [16.  ],\n",
       "       [30.  ],\n",
       "       [34.5 ],\n",
       "       [17.  ],\n",
       "       [42.  ],\n",
       "       [  nan],\n",
       "       [35.  ],\n",
       "       [28.  ],\n",
       "       [  nan],\n",
       "       [ 4.  ],\n",
       "       [74.  ],\n",
       "       [ 9.  ],\n",
       "       [16.  ],\n",
       "       [44.  ],\n",
       "       [18.  ],\n",
       "       [45.  ],\n",
       "       [51.  ],\n",
       "       [24.  ],\n",
       "       [  nan],\n",
       "       [41.  ],\n",
       "       [21.  ],\n",
       "       [48.  ],\n",
       "       [  nan],\n",
       "       [24.  ],\n",
       "       [42.  ],\n",
       "       [27.  ],\n",
       "       [31.  ],\n",
       "       [  nan],\n",
       "       [ 4.  ],\n",
       "       [26.  ],\n",
       "       [47.  ],\n",
       "       [33.  ],\n",
       "       [47.  ],\n",
       "       [28.  ],\n",
       "       [15.  ],\n",
       "       [20.  ],\n",
       "       [19.  ],\n",
       "       [  nan],\n",
       "       [56.  ],\n",
       "       [25.  ],\n",
       "       [33.  ],\n",
       "       [22.  ],\n",
       "       [28.  ],\n",
       "       [25.  ],\n",
       "       [39.  ],\n",
       "       [27.  ],\n",
       "       [19.  ],\n",
       "       [  nan],\n",
       "       [26.  ],\n",
       "       [32.  ]])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "owned-easter",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_2.loc[:,\"Age\"] = data_2.loc[:,\"Age\"].fillna(data_2.loc[:,\"Age\"].median())\n",
    "#threshold 38以上的划为1，以下的划为0\n",
    "transformer = Binarizer(threshold=38).fit_transform(X) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "incomplete-pitch",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.]])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "solar-setup",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_2.iloc[:,0] = transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "secondary-farmer",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>male</td>\n",
       "      <td>S</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>female</td>\n",
       "      <td>C</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>female</td>\n",
       "      <td>S</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>female</td>\n",
       "      <td>S</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>male</td>\n",
       "      <td>S</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Age     Sex Embarked Survived\n",
       "0  0.0    male        S       No\n",
       "1  0.0  female        C      Yes\n",
       "2  0.0  female        S      Yes\n",
       "3  0.0  female        S      Yes\n",
       "4  0.0    male        S       No"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "offensive-harvey",
   "metadata": {},
   "source": [
    "- **preprocessing.KBinsDiscretizer**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ranking-florida",
   "metadata": {},
   "source": [
    "这是将连续型变量划分为分类变量的类，能够将连续型变量排序后按顺序分箱后编码。总共包含三个重要参数："
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "funky-choir",
   "metadata": {},
   "source": [
    "![image.png](https://pic4.zhimg.com/80/v2-12ed73205151ff8f4ae57ce0ba5aac03_720w.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "developing-invalid",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import KBinsDiscretizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "weekly-soundtrack",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_3 = data_.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "continuing-astronomy",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22.0</td>\n",
       "      <td>male</td>\n",
       "      <td>S</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38.0</td>\n",
       "      <td>female</td>\n",
       "      <td>C</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>26.0</td>\n",
       "      <td>female</td>\n",
       "      <td>S</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>35.0</td>\n",
       "      <td>female</td>\n",
       "      <td>S</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>35.0</td>\n",
       "      <td>male</td>\n",
       "      <td>S</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Age     Sex Embarked Survived\n",
       "0  22.0    male        S       No\n",
       "1  38.0  female        C      Yes\n",
       "2  26.0  female        S      Yes\n",
       "3  35.0  female        S      Yes\n",
       "4  35.0    male        S       No"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "robust-preserve",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data_3.iloc[:,0].values.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "million-responsibility",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [2.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [2.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [2.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [2.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [2.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [2.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [2.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [2.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [2.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [2.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [2.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [2.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [2.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [2.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [2.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.]])"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "est = KBinsDiscretizer(n_bins=3, encode='ordinal', strategy='uniform')\n",
    "est.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "unknown-remove",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0.0, 1.0, 2.0}"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#查看转换后分的箱：变成了一列中的三箱\n",
    "set(est.fit_transform(X).ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "complex-asset",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       ...,\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.]])"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "est = KBinsDiscretizer(n_bins=3, encode='onehot', strategy='uniform')\n",
    "#查看转换后分的箱：变成了哑变量\n",
    "est.fit_transform(X).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "collect-potential",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
